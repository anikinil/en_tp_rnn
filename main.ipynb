{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Machine Translation using Sequence-to-Sequence Learning\n","\n","<h2 class=\"pm-node nj-subtitle\">An Annotated Introduction to LSTM-based Encoder-Decoder Models</h2>\n","\n","In this article we're training a Recurrent Neural Network (RNN) model based on two *[Long Short-Term Memory](https://en.wikipedia.org/wiki/Long_short-term_memory)* (LSTM) layers to translate English sentences to German inspired by [a tutorial](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html) on the official Keras blog. For an overview of RNNs and a more detailed look at LSTMs, please refer to [this great blogpost](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) by Chris Olah.\n","\n","In sequence-to-sequence learning we want to convert input sequences, in the general case of arbitraty length, to sequences in another domain. An obvious application of this is machine translation.\n","\n","`'Go on.' -> [Sequence-to-Sequence Model] -> 'Mach weiter.'`\n","\n","The model we're building will be processing the English sentences as a sequence of characters and produce the translated sentences character by character.\n","\n","![Seq2Seq Model Animation.gif](https://nextjournal.com/data/Qmc1KsqbPiPqP6dyA3niRnZ4StznJzx28d9FRdipYEZJx4?content-type=image/gif&node-id=794070c6-5f44-4e26-bcd8-b55566cc5c95&filename=Seq2Seq+Model+Animation.gif&node-kind=file)\n","\n","Note that more advanced machine translation models are usually processing sentences word by word. However, this would require us to first embed each word as a vector. For simplicity reasons we'll stick to the character by character basis here.\n","\n","# Data Preparation\n","\n","Luckily there are quite a few datasets for language translation tasks available [here](http://www.manythings.org/anki/). They all consist of sentence pairs delimited by tabs. The German-English dataset contains [reference](#nextjournal#reference#2f2342b2-e718-47bf-8fc8-81dcf6793174) sentence pairs prepared by the [Tatoeba Project](https://tatoeba.org/eng). Before we can feed English sentences to the model, they must first be conformed for use as input to Keras' LSTM layers.\n","\n","The dataset is already uploaded as `deu-eng.txt`. The sentence pairs can be loaded by creating a reference (via `@...`) in the Python runtime.\n","\n","[deu-eng.txt](https://nextjournal.com/data/QmZcwGAA2J1crr4ha8zBG6sUae2ZVN4P2jJiJcw8aRNc2n?content-type=text/plain&node-id=8275fa8c-24e2-4fcc-95c9-a074458b7ed8&filename=deu-eng.txt&node-kind=file)\n","\n","Let's create a list of lines by splitting the text file at every occurance of `'\\n'`."]},{"cell_type":"code","execution_count":1,"metadata":{"nextjournal":{"id":"3bd77b5d-06af-49d5-89c7-36aace8fc174","kind":"code","language":"python"}},"outputs":[],"source":["with open(\n","  'corpus.txt'\n",", 'r', encoding='utf-8') as f:\n","  lines = f.read().split('\\n')"]},{"cell_type":"markdown","metadata":{},"source":["Let's look at an example."]},{"cell_type":"code","execution_count":2,"metadata":{"nextjournal":{"id":"1397847a-8a78-400f-809c-4bbd5f8b30fb","kind":"code","language":"python"}},"outputs":[{"data":{"text/plain":["'This is a well-formed vase.\\tpoki ni li pona lukin.'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["lines[155]"]},{"cell_type":"markdown","metadata":{},"source":["Sweet! So we have both the input (English) and the target (German) sentences in every line, separated by `'\\t'`."]},{"cell_type":"code","execution_count":3,"metadata":{"nextjournal":{"id":"79ddf54b-429a-42c8-83f3-337e2ef53e8f","kind":"code","language":"python"}},"outputs":[{"data":{"text/plain":["30231"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["len(lines)"]},{"cell_type":"markdown","metadata":{},"source":["Let's go ahead and split each line into input text and target text. Since we'll do the translation character by character we also want to compute a set of every character we encounter in the dataset, both for inputs as well as targets."]},{"cell_type":"code","execution_count":4,"metadata":{"nextjournal":{"id":"706a06f5-78ea-40df-a0b5-ff0d7e7b4f02","kind":"code","language":"python"}},"outputs":[],"source":["input_texts = []\n","target_texts = []\n","input_characters = set()\n","target_characters = set()"]},{"cell_type":"markdown","metadata":{},"source":["Now we can loop over every sample we choose for training and fill the lists and sets. We'll also add `'\\t'` (*start-of-sequence*) and `'\\n'` (*end-of-sequence*) characters to every target text. This will later help our model determine when to start and - more importantly - end sequences. We need this due to the fact that we don't know a-priori how long the output sequences should be. That's why we teach our model to decide on that by itself."]},{"cell_type":"code","execution_count":5,"metadata":{"nextjournal":{"id":"ed0e0161-bd7d-4efd-93a2-aef4dc0c64bb","kind":"code","language":"python"}},"outputs":[{"data":{"text/plain":["25000"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["num_samples = 25000\n","num_samples"]},{"cell_type":"code","execution_count":6,"metadata":{"nextjournal":{"id":"dbd62d02-a197-430e-8482-f3c6cf6a214e","kind":"code","language":"python"}},"outputs":[],"source":["for line in lines[: min(num_samples, len(lines) - 1)]:\n","  input_text, target_text = line.split('\\t')\n","  target_text = '\\t' + target_text + '\\n'\n","  input_texts.append(input_text)\n","  target_texts.append(target_text)\n","  for char in input_text:\n","    if char not in input_characters:\n","      input_characters.add(char)\n","  for char in target_text:\n","    if char not in target_characters:\n","      target_characters.add(char)"]},{"cell_type":"code","execution_count":7,"metadata":{"nextjournal":{"id":"71881aa1-6aaf-4514-a7c9-ed21c9ea25bc","kind":"code","language":"python"}},"outputs":[{"data":{"text/plain":["'This is a well-formed vase.'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["input_texts[155]"]},{"cell_type":"code","execution_count":8,"metadata":{"nextjournal":{"id":"1a7c59d7-6717-45a0-a6f2-46410bbe649f","kind":"code","language":"python"}},"outputs":[{"data":{"text/plain":["'\\tpoki ni li pona lukin.\\n'"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["target_texts[155]"]},{"cell_type":"markdown","metadata":{},"source":["Ok, let's look at some characteristics the input and target sequences."]},{"cell_type":"code","execution_count":9,"metadata":{"nextjournal":{"id":"17881553-d7bd-4573-a980-8217170e5774","kind":"code","language":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of samples: 25000\n","Number of unique input tokens: 96\n","Number of unique output tokens: 69\n","Max sequence length for inputs: 849\n","Max sequence length for outputs: 647\n"]}],"source":["input_characters = sorted(list(input_characters))\n","target_characters = sorted(list(target_characters))\n","num_encoder_tokens = len(input_characters)\n","num_decoder_tokens = len(target_characters)\n","max_encoder_seq_length = max([len(txt) for txt in input_texts])\n","max_decoder_seq_length = max([len(txt) for txt in target_texts])\n","\n","print('Number of samples:', len(input_texts))\n","print('Number of unique input tokens:', num_encoder_tokens)\n","print('Number of unique output tokens:', num_decoder_tokens)\n","print('Max sequence length for inputs:', max_encoder_seq_length)\n","print('Max sequence length for outputs:', max_decoder_seq_length)"]},{"cell_type":"code","execution_count":10,"metadata":{"nextjournal":{"id":"f126bb18-7c37-46b4-bf57-457a87c7157d","kind":"code","language":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["[' ', '!', '\"', '$', \"'\", '(', ')', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xa0', '°', 'ß', 'â', 'ã', 'é', 'í', 'ó', 'ü', 'ʈ', '–', '—', '’', '“', '”', '€', '☭', '\\ufeff']\n"]}],"source":["print(input_characters)"]},{"cell_type":"markdown","metadata":{},"source":["By now we have [reference](#nextjournal#reference#84f5f376-ad88-4700-86c1-1784e01240b7) samples consisting of input/target texts. Along the input texts we have 70 unique characters, while the target texts contain 87 unique characters."]},{"cell_type":"code","execution_count":11,"metadata":{"nextjournal":{"id":"a5ee9c18-2bfd-4a9e-905b-4086fb5ba2df","kind":"code","language":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["['\\t', '\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '/', '0', '1', '2', '4', '5', '9', ':', ';', '?', 'A', 'B', 'C', 'E', 'F', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'S', 'T', 'U', 'W', 'Y', 'a', 'b', 'c', 'd', 'e', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'w', 'y', 'ß', 'â', 'Ʈ', '–', '—', '“', '”', '„', '☭']\n"]}],"source":["print(target_characters)"]},{"cell_type":"markdown","metadata":{},"source":["This is, in part, due to these weird [German umlauts](https://en.wikipedia.org/wiki/Germanic_umlaut).\n","\n","Another characteristic for the German language is that sentences tend to be a bit longer than their English counterparts (maybe you can find a way to test that hypothesis for yourself). In any case, the longest target sequence in the 10000 sample sentences we're using contains 53 characters, while the longest input sequence only contains 16.\n","\n","But these input texts still don't work as input to our model. We'll need to convert the characters into numeric values. In our case, one-hot encodings are fine, but when turning to more involved models, using more advanced embedding methods such as [Word2Vec](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf) would make more sense. \n","\n","Here we first tokenize our characters by assigning each unique character to an integer value."]},{"cell_type":"code","execution_count":12,"metadata":{"nextjournal":{"id":"163950fa-c606-4e96-b75b-280eb0e443fd","kind":"code","language":"python"}},"outputs":[],"source":["input_token_index = dict(\n","  [(char, i) for i, char in enumerate(input_characters)])\n","target_token_index = dict(\n","  [(char, i) for i, char in enumerate(target_characters)])"]},{"cell_type":"markdown","metadata":{},"source":["With that we can start creating numeric data. We'll need input data for both the encoder and the decoder of the model, as well as the target data (used only in the decoder part)."]},{"cell_type":"code","execution_count":13,"metadata":{"nextjournal":{"id":"a66de03c-e007-4e23-a107-eda95b659686","kind":"code","language":"python"}},"outputs":[],"source":["import numpy as np\n","\n","encoder_input_data = np.zeros(\n","  (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n","  dtype='float32')\n","decoder_input_data = np.zeros(\n","  (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n","  dtype='float32')\n","decoder_target_data = np.zeros(\n","  (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n","  dtype='float32')"]},{"cell_type":"code","execution_count":14,"metadata":{"nextjournal":{"id":"da1a59b6-dc60-4f27-a939-669d2babb80c","kind":"code","language":"python"}},"outputs":[{"data":{"text/plain":["(25000, 849, 96)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["encoder_input_data.shape"]},{"cell_type":"code","execution_count":15,"metadata":{"nextjournal":{"id":"26c7f68c-0a76-488e-88af-3ccc1086610e","kind":"code","language":"python"}},"outputs":[{"data":{"text/plain":["(25000, 647, 69)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["decoder_input_data.shape"]},{"cell_type":"markdown","metadata":{},"source":["The `encoder_input_data` will consist of [reference](#nextjournal#reference#ce846325-b878-4486-baf4-de4b9ca43c05) samples of the maximum sequence length (16) filled with the respective one-hot-encoded tokens (in this case a vector of length 70).\n","\n","The `decoder_input_data` and the `decoder_target_data` are both constructed in the same way as the input data for the encoder. We need to construct those two sequences because we're training our model through a process called *teacher forcing*, where the decoder learns to generate `decoder_target_data[t+1...]` given `decoder_input_data[...t]` while taking into account the input sequence via the encoder's internal state. Therefore we have to offset `decoder_target_data` by one timestep.\n","\n","Time to fill in the data with the actual tokens. For that we iterate over all input and target texts and insert the respective one-hot encoding each character in the sequence. "]},{"cell_type":"code","execution_count":16,"metadata":{"nextjournal":{"id":"fd3c6c92-740e-4b3d-9412-03fab04d2043","kind":"code","language":"python"}},"outputs":[],"source":["for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n","  for t, char in enumerate(input_text):\n","    encoder_input_data[i, t, input_token_index[char]] = 1.\n","  for t, char in enumerate(target_text):\n","    # decoder_target_data is ahead of decoder_input_data by one timestep\n","    decoder_input_data[i, t, target_token_index[char]] = 1.\n","    if t > 0:\n","      # decoder_target_data will be ahead by one timestep\n","      # and will not include the start character.\n","      decoder_target_data[i, t - 1, target_token_index[char]] = 1."]},{"cell_type":"markdown","metadata":{},"source":["With that our example sentence [reference](#nextjournal#reference#1c47e549-367c-4fc3-92fa-0f8f54e60da2) turned into a sequence of length 16 with one-hot encodings of tokens for every character."]},{"cell_type":"code","execution_count":17,"metadata":{"nextjournal":{"id":"ae6e9ac8-6b93-4531-bfb1-7d4273611f53","kind":"code","language":"python"}},"outputs":[{"data":{"text/plain":["(849, 96)"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["encoder_input_data[155].shape"]},{"cell_type":"markdown","metadata":{},"source":["# Building the Model\n","\n","Now it's time to take a closer look at our encoder-decoder model. Our model will consist of two LSTMs. One will serve as an encoder, encoding the input sequence and producing internal state vectors which serve as conditioning for the decoder. The decoder, another LSTM, is responsible for predicting the individual characters of the target sequence. Its initial state is set to the state vectors from the encoder. This passes information about what to generate from the encoder to the decoder. \n","\n","![Encoder-Decoder Model.png](https://nextjournal.com/data/QmSAGUejc3K95ZiLErFRG8h18epbxmEs4crg97Jx7GtbC3?content-type=image/png&node-id=6fe8c463-26fc-4fb7-a6cf-b3e57459bbdc&filename=Encoder-Decoder+Model.png&node-kind=file)\n","\n","Let's build this model using `Keras`. For that we'll need the `LSTM` layer, as well as a `Dense` layer."]},{"cell_type":"code","execution_count":18,"metadata":{"nextjournal":{"id":"922ca13f-d75f-4146-bbd5-a1d3141b8907","kind":"code","language":"python"}},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-05-13 21:54:50.817559: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-05-13 21:54:50.957415: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-05-13 21:54:51.503279: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["import keras, tensorflow\n","from keras.models import Model\n","from keras.layers import Input, LSTM, Dense\n","import numpy as np"]},{"cell_type":"markdown","metadata":{},"source":["Before building the encoder and decoder parts we first have to define some hyperparameters. Since the dimensionality for the encoder and decoder LSTM layers have to match, one parameter, `latent_dim`, is fine here."]},{"cell_type":"code","execution_count":19,"metadata":{"nextjournal":{"id":"a9478c52-04d4-4bdf-9ca7-85ca4bdfd0a1","kind":"code","language":"python"}},"outputs":[],"source":["batch_size = 64  # batch size for training\n","epochs = 1  # number of epochs to train for\n","latent_dim = 512  # latent dimensionality of the encoding space"]},{"cell_type":"markdown","metadata":{},"source":["With that we can start building the model. First we have to construct the encoder. When creating the LSTM layer we have to pay attention to set the `return_state` argument to true, since we want to use the encoder's internal state vectors for the decoder."]},{"cell_type":"code","execution_count":20,"metadata":{"nextjournal":{"id":"45693bc9-32d8-4991-8079-20bac84f7a65","kind":"code","language":"python"}},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-05-13 21:54:53.990202: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"]}],"source":["encoder_inputs = Input(shape=(None, num_encoder_tokens))\n","encoder = LSTM(latent_dim, return_state=True)\n","encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n","encoder_states = [state_h, state_c]"]},{"cell_type":"markdown","metadata":{},"source":["Note that we discard `encoder_outputs` as depicted in the schematic overview above since we're only interested in the state vectors.\n","\n","Using `encoder_states` we can now build the decoder. Again we'll use [Keras' Input layer](https://keras.io/layers/core/#input) to be flexible concerning input sequence lengths. When creating the LSTM, we now want it to return full output sequences as well as the internal state vectors. We're not using the decoder's internal states during training, but we will need them later for inference.\n","\n","To arrive at the individual characters from the decoder's output we attach a [Dense layer](https://keras.io/layers/core/#dense) to the decoder's LSTM outputs where the number of units match the number of decoder tokens. This way we can just use a softmax activation for the dense layer's outputs and train the whole model using a categorical cross-entropy loss - a standard choice for classification problems."]},{"cell_type":"code","execution_count":21,"metadata":{"nextjournal":{"id":"64ee66c7-5da1-4b49-b9a3-a40e5b9872b1","kind":"code","language":"python"}},"outputs":[],"source":["decoder_inputs = Input(shape=(None, num_decoder_tokens))\n","decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n","                                     initial_state=encoder_states)\n","decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)"]},{"cell_type":"markdown","metadata":{},"source":["Now let's glue both parts together using [Keras' Model](https://keras.io/models/model/) functional API. Specify the inputs needed to produce the outputs and the resulting model will automatically include all layers necessary to compute the outputs. "]},{"cell_type":"code","execution_count":22,"metadata":{"nextjournal":{"id":"1e35f556-99c4-4404-aef6-80eecef36cd2","kind":"code","language":"python"}},"outputs":[],"source":["model = Model(inputs=[encoder_inputs, decoder_inputs], \n","              outputs=decoder_outputs)"]},{"cell_type":"markdown","metadata":{},"source":["# Training the Model\n","\n","Let's compile the model defining the optimizer and our cross-entropy loss. As a cross-check we can also print out a summary of the individual layers included in our model."]},{"cell_type":"code","execution_count":23,"metadata":{"nextjournal":{"id":"b65c43c9-581a-4cd0-8ae6-56bb5a5db08a","kind":"code","language":"python"}},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"functional_1\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">69</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>),    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,591,616</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n","│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>),     │            │                   │\n","│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)]     │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,481,024</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n","│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],       │\n","│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]        │\n","│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)]            │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">69</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">70,725</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m69\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m),    │  \u001b[38;5;34m4,591,616\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n","│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m),     │            │                   │\n","│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)]     │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │  \u001b[38;5;34m4,481,024\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n","│                     │ \u001b[38;5;34m1024\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,     │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],       │\n","│                     │ \u001b[38;5;34m1024\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,     │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]        │\n","│                     │ \u001b[38;5;34m1024\u001b[0m)]            │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m69\u001b[0m)  │     \u001b[38;5;34m70,725\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,143,365</span> (34.88 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,143,365\u001b[0m (34.88 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,143,365</span> (34.88 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,143,365\u001b[0m (34.88 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n","model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["No surprises here. `lstm_1`, our encoder, takes as input the first input layer, while the decoder, `lstm_2`, uses the encoder's internal states as well as the second input layer. Our model has about 700.000 parameters in total! \n","\n","Time to run the training! Since we're running a CPU-only instance, the training will take about 1 hour (compared to only about 20 minutes when using a GPU). The patient reader can un-comment the following cell to run the training. We'll skip it and simply load the weights of a pre-trained model."]},{"cell_type":"code","execution_count":24,"metadata":{"nextjournal":{"id":"2f3e4e48-e713-44dd-9717-e01220914f14","kind":"code","language":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n","\u001b[1m  2/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44:45\u001b[0m 9s/step - loss: 0.2173 "]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mencoder_input_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_input_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_target_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model_results = model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          validation_split=0.2)\n","model.save('model.keras')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["\n","import matplotlib.pyplot as plt\n","\n","plt.plot(model_results.history['loss'])\n","plt.plot(model_results.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'val'], loc='upper left')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["[seq2seq_eng-ger.h5](https://nextjournal.com/data/QmdLreGq3MREE65Agbw3WEYfxecJ8X5ED8ymBJY7FnRyVA?content-type=application/x-hdf&node-id=a11b7a60-0d2b-49a8-b9b4-05a9cfcecd46&filename=seq2seq_eng-ger.h5&node-kind=file)\n","\n","# Testing the Machine Translation\n","\n","Since we're impatient by nature, we'll simply use the pre-trained weights. Lets load them."]},{"cell_type":"code","execution_count":null,"metadata":{"nextjournal":{"id":"eb9b4466-ba29-4e57-b2e6-e104ac1c4614","kind":"code","language":"python"}},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ilja/.local/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 10 variables. \n","  saveable.load_own_variables(weights_store.get(inner_path))\n"]}],"source":["model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n","model.load_weights('model.keras')"]},{"cell_type":"markdown","metadata":{},"source":["Ok, with the weights in place it's time to test our machine translation model by translating a few test sentences.\n","\n","The inference mode works a bit differently than the training procedure. The procedure can be broken down into 4 steps:\n","\n","1\\. Encode the input sequence, return its internal states.\n","\n","2\\. Run the decoder using just the *start-of-sequence* character as input and the encoder internal states as the decoder's initial states.\n","\n","3\\. Append the character predicted (after lookup of the token) by the decoder to the decoded sequence.\n","\n","4\\. Repeat the process with the previously predicted character token as input and updates internal states.\n","\n","![Inference Process.png](https://nextjournal.com/data/QmaQiZ99Jb3RFP2Mpp15YW1vVKDqsXiEFnDBDGULGc4q16?content-type=image/png&node-id=5138d692-bb12-438d-8b74-b0e7ad069b28&filename=Inference+Process.png&node-kind=file)\n","\n","Let's go ahead and implement this. Since we only need the encoder for encoding the input sequence we'll split encoder and decoder into two separate models."]},{"cell_type":"code","execution_count":null,"metadata":{"nextjournal":{"id":"28439d61-43a3-4ee1-a767-731e6ccfdcfa","kind":"code","language":"python"}},"outputs":[],"source":["encoder_model = Model(encoder_inputs, encoder_states)\n","\n","decoder_state_input_h = Input(shape=(latent_dim,))\n","decoder_state_input_c = Input(shape=(latent_dim,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","\n","decoder_outputs, state_h, state_c = decoder_lstm(\n","  decoder_inputs, initial_state=decoder_states_inputs)\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","decoder_model = Model(\n","  [decoder_inputs] + decoder_states_inputs,\n","  [decoder_outputs] + decoder_states)"]},{"cell_type":"markdown","metadata":{},"source":["In order to conveniently perform the lookup from step 3 above we'll create reverse-lookup dictionaries for both the input and target tokens."]},{"cell_type":"code","execution_count":null,"metadata":{"nextjournal":{"id":"3eef4c19-9982-4d1f-be1b-f635c185e311","kind":"code","language":"python"}},"outputs":[],"source":["# reverse-lookup token index to turn sequences back to characters\n","reverse_input_char_index = dict(\n","  (i, char) for char, i in input_token_index.items())\n","reverse_target_char_index = dict(\n","  (i, char) for char, i in target_token_index.items())"]},{"cell_type":"markdown","metadata":{},"source":["With that we can create a function to perform the whole process of decoding a given input sequence (inputs already tokenized)."]},{"cell_type":"code","execution_count":null,"metadata":{"nextjournal":{"id":"553eab80-46ce-4c69-9f61-e7b61c47f5bb","kind":"code","language":"python"}},"outputs":[],"source":["def decode_sequence(input_seq):\n","  # encode the input sequence to get the internal state vectors.\n","  states_value = encoder_model.predict(input_seq, verbose=0)\n","  \n","  # generate empty target sequence of length 1 with only the start character\n","  target_seq = np.zeros((1, 1, num_decoder_tokens))\n","  target_seq[0, 0, target_token_index['\\t']] = 1.\n","  \n","  # output sequence loop\n","  stop_condition = False\n","  decoded_sentence = ''\n","  while not stop_condition:\n","    output_tokens, h, c = decoder_model.predict([target_seq] + states_value, verbose=0)\n","    \n","    # sample a token and add the corresponding character to the \n","    # decoded sequence\n","    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","    sampled_char = reverse_target_char_index[sampled_token_index]\n","    decoded_sentence += sampled_char\n","    \n","    # check for the exit condition: either hitting max length\n","    # or predicting the 'stop' character\n","    if (sampled_char == '\\n' or \n","        len(decoded_sentence) > max_decoder_seq_length):\n","      stop_condition = True\n","      \n","    # update the target sequence (length 1).\n","    target_seq = np.zeros((1, 1, num_decoder_tokens))\n","    target_seq[0, 0, sampled_token_index] = 1.\n","    \n","    # update states\n","    states_value = [h, c]\n","    \n","  return decoded_sentence"]},{"cell_type":"markdown","metadata":{},"source":["With that let's sample a few test cases! "]},{"cell_type":"code","execution_count":null,"metadata":{"nextjournal":{"id":"c5329f01-27a1-4f2c-ad0c-3837bc52399a","kind":"code","language":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["-\n","Input sentence: ﻿I have to go to sleep.\n","Decoded sentence: min       lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll\n","-\n","Input sentence: Most people think I'm crazy.\n","Decoded sentence: min       lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll\n","-\n","Input sentence: I love you.\n","Decoded sentence: min       lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll\n","-\n","Input sentence: Would you like something to drink?\n","Decoded sentence: min       lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll\n","-\n","Input sentence: Do you speak Italian?\n","Decoded sentence: min       lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll\n","-\n","Input sentence: He's very sexy.\n","Decoded sentence: min       lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll\n","-\n","Input sentence: Computers make people stupid.\n","Decoded sentence: min       lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll\n","-\n","Input sentence: Life is beautiful.\n","Decoded sentence: min       lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll\n","-\n","Input sentence: Where is the bathroom?\n","Decoded sentence: min       lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll\n","-\n","Input sentence: I want an MP3 player!\n","Decoded sentence: min       lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll\n"]}],"source":["for seq_index in range(10):\n","  input_seq = encoder_input_data[seq_index: seq_index + 1]\n","  decoded_sentence = decode_sequence(input_seq)\n","  print('-')\n","  print('Input sentence:', input_texts[seq_index])\n","  print('Decoded sentence:', decoded_sentence)"]},{"cell_type":"markdown","metadata":{},"source":["Not bad for a model consisting only of two LSTM layers and a linear one! \n","\n","But those were all examples from the training set. Let's validate the model using our own example: Let's have the model translate something simple, like:\n","\n","`\"How are you?\"`\n","\n","We'll put all the tokenization and decoding into one cell and print out the decoded sequence."]},{"cell_type":"code","execution_count":null,"metadata":{"nextjournal":{"id":"14616df3-a559-42d7-99e8-297f31f820c4","kind":"code","language":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["How are you?\n","min       lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll\n"]}],"source":["input_sentence = \"How are you?\"\n","test_sentence_tokenized = np.zeros(\n","  (1, max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n","for t, char in enumerate(input_sentence):\n","  test_sentence_tokenized[0, t, input_token_index[char]] = 1.\n","print(input_sentence)\n","print(decode_sequence(test_sentence_tokenized))"]},{"cell_type":"markdown","metadata":{},"source":["Great! But surely this simple model trained on 10k examples will have some failure cases! Let's try out some examples the model didn't see during training."]},{"cell_type":"code","execution_count":null,"metadata":{"nextjournal":{"id":"f60adaea-4449-4657-a101-b1cffe2f3c6f","kind":"code","language":"python"}},"outputs":[],"source":["val_input_texts = []\n","val_target_texts = []\n","line_ix = 12000\n","for line in lines[line_ix:line_ix+10]:\n","  input_text, target_text = line.split('\\t')\n","  val_input_texts.append(input_text)\n","  val_target_texts.append(target_text)\n","\n","val_encoder_input_data = np.zeros(\n","  (len(val_input_texts), max([len(txt) for txt in val_input_texts]),\n","   num_encoder_tokens), dtype='float32')\n","\n","for i, input_text in enumerate(val_input_texts):\n","  for t, char in enumerate(input_text):\n","    val_encoder_input_data[i, t, input_token_index[char]] = 1."]},{"cell_type":"code","execution_count":null,"metadata":{"nextjournal":{"id":"d6e7b3b7-02fc-4179-bf02-3e8efbe1bd42","kind":"code","language":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["-\n","Input sentence: Tom is a senior.\n","Decoded sentence: min       llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll\n","Ground Truth sentence: jan Ton li jan pi sike suno mute.\n","-\n","Input sentence: I have no quarrel with Tom.\n","Decoded sentence: min       llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll\n","Ground Truth sentence: mi en jan Ton li jo ala e utala.\n","-\n","Input sentence: Just give it to me.\n","Decoded sentence: min       llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll\n","Ground Truth sentence: o pana taso e ona tawa mi.\n","-\n","Input sentence: I need to go get some money out of the bank.\n","Decoded sentence: min       llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll\n","Ground Truth sentence: mi wile kama jo e mani tan tomo mani.\n","-\n","Input sentence: Do you happen to know the time?\n","Decoded sentence: min       llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll\n","Ground Truth sentence: sina sona ala sona e tenpo?\n","-\n","Input sentence: Is there anybody in there?\n","Decoded sentence: min       llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll\n","Ground Truth sentence: jan li lon ni anu seme?\n","-\n","Input sentence: I use the computer.\n","Decoded sentence: min       llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll\n","Ground Truth sentence: mi kepeken e ilo sona.\n","-\n","Input sentence: I cut bread.\n","Decoded sentence: min       llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll\n","Ground Truth sentence: mi tu e pan.\n","-\n","Input sentence: Listen to me, all of you.\n","Decoded sentence: min       llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll\n","Ground Truth sentence: sina ali o kute e mi.\n","-\n","Input sentence: Shun will take over my job while I'm away.\n","Decoded sentence: min       llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll\n","Ground Truth sentence: mi weka la jan Sun li pali e pali mi.\n"]}],"source":["for seq_index in range(10):\n","  input_seq = val_encoder_input_data[seq_index: seq_index + 1]\n","  decoded_sentence = decode_sequence(input_seq)\n","  print('-')\n","  print('Input sentence:', val_input_texts[seq_index])\n","  print('Decoded sentence:', decoded_sentence[:-1])\n","  print('Ground Truth sentence:', val_target_texts[seq_index])"]},{"cell_type":"markdown","metadata":{},"source":["Ok, that clearly shows some failure cases. Note that for the evaluation texts we had input sequences longer than the longest sequence in the training set."]},{"cell_type":"code","execution_count":null,"metadata":{"nextjournal":{"id":"0f3910e7-f41d-45eb-a6e3-686bf651bd49","kind":"code","language":"python"}},"outputs":[{"data":{"text/plain":["44"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["max([len(txt) for txt in val_input_texts])"]},{"cell_type":"markdown","metadata":{},"source":["While the model is able to produce a decoded sequence for these inputs, it will produce worse outputs the longer the input sequences become. After all, the model was not trained to decode sequences that long. You can try this out by changing the `line_ix` parameter to something later in the dataset (maybe something around 50000).\n","\n","# Summary and Outlook\n","\n","This article showed the capabilities of encoder-decoder models combined with LSTM layers for sequence-to-sequence learning.\n","\n","The dataset consisted of English-German sentence pairs. All characters of the respective sentences were first tokenized. The sequences of tokenized characters were then used as input and target for the encoder-decoder model.\n","\n","During training we used the teacher forcing method where we offset the decoders input and target by one timestep. For inference, we used a slightly different setup, but still used the same modules we trained earlier. The input sequence was processed by the encoder and its final hidden states, along with the start-of-sequence character, were used as input for the decoder. Each predicted character was then fed back into the decoder while the hidden states were updated. We repeated this until the decoder predicted the end-of-sequence character telling us the predicted sequence is complete.\n","\n","While this model is a rather simple and far away from state-of-the-art neural machine translation models it still shows some principles still used in more recent approaches (e.g. encoder-decoder models in the infamous [Attention Is All You Need](https://arxiv.org/abs/1706.03762) paper). Even [Google Translate](https://arxiv.org/abs/1609.08144) seems to be using a more sophisticated encoder-decoder model based on (bidirectional) LSTMs.\n","\n","Going further, turning the LSTMs we used into their bidirectional version might  help improve the model. To become even better, one might want to turn to methods such as *self-attention* (described for example in a great [blogpost on distill.pub](https://distill.pub/2016/augmented-rnns/)) and embed them in the encoder-decoder structure."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"nextjournal":{"nodes-edn":"{\"a9478c52-04d4-4bdf-9ca7-85ca4bdfd0a1\" {:content \"batch_size = 64  # batch size for training\\nepochs = 100  # number of epochs to train for\\nlatent_dim = 256  # latent dimensionality of the encoding space\", :output-log-lines {:stdout 0}, :language \"python\", :id \"a9478c52-04d4-4bdf-9ca7-85ca4bdfd0a1\", :compute-ref #uuid \"a30bc62b-5730-498d-8443-36353c21880b\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 191, :bucket nil}, \"1c47e549-367c-4fc3-92fa-0f8f54e60da2\" {:ref-id \"71881aa1-6aaf-4514-a7c9-ed21c9ea25bc\", :ref-kind \"output\", :id \"1c47e549-367c-4fc3-92fa-0f8f54e60da2\", :kind \"reference\"}, \"71881aa1-6aaf-4514-a7c9-ed21c9ea25bc\" {:content \"input_texts[155]\", :output-log-lines {:stdout 0}, :language \"python\", :id \"71881aa1-6aaf-4514-a7c9-ed21c9ea25bc\", :compute-ref #uuid \"e0e6bc11-478e-44fe-844d-fe07fb6d7f70\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 246, :bucket nil}, \"ce846325-b878-4486-baf4-de4b9ca43c05\" {:ref-id \"ed0e0161-bd7d-4efd-93a2-aef4dc0c64bb\", :ref-kind \"output\", :id \"ce846325-b878-4486-baf4-de4b9ca43c05\", :kind \"reference\"}, \"1cabb6d9-48c8-41a1-9cbe-a58a7a870bce\" {:id \"1cabb6d9-48c8-41a1-9cbe-a58a7a870bce\", :kind \"reference\", :link [:output \"8275fa8c-24e2-4fcc-95c9-a074458b7ed8\" \"deu-eng.txt\"]}, \"2f3e4e48-e713-44dd-9717-e01220914f14\" {:content \"'''\\nmodel.fit([encoder_input_data, decoder_input_data], decoder_target_data,\\n          batch_size=batch_size,\\n          epochs=epochs,\\n          validation_split=0.2)\\nmodel.save('/results/seq2seq_eng-ger.h5')\\n'''\", :output-log-lines {:stdout 0}, :language \"python\", :id \"2f3e4e48-e713-44dd-9717-e01220914f14\", :compute-ref #uuid \"cc085c3d-779e-4bdd-bb50-7ee532d08a41\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 176, :bucket nil}, \"3bd77b5d-06af-49d5-89c7-36aace8fc174\" {:content \"with open($$ref{{[\\\"~:output\\\",\\\"8275fa8c-24e2-4fcc-95c9-a074458b7ed8\\\",\\\"deu-eng.txt\\\"]}}, 'r', encoding='utf-8') as f:\\n  lines = f.read().split('\\\\n')\", :output-log-lines {:stdout 0}, :language \"python\", :id \"3bd77b5d-06af-49d5-89c7-36aace8fc174\", :compute-ref #uuid \"1e177681-1683-4278-a1ee-88480709c50b\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 644, :bucket nil}, \"2f2342b2-e718-47bf-8fc8-81dcf6793174\" {:ref-id \"79ddf54b-429a-42c8-83f3-337e2ef53e8f\", :ref-kind \"output\", :id \"2f2342b2-e718-47bf-8fc8-81dcf6793174\", :kind \"reference\"}, \"f60adaea-4449-4657-a101-b1cffe2f3c6f\" {:content \"val_input_texts = []\\nval_target_texts = []\\nline_ix = 12000\\nfor line in lines[line_ix:line_ix+10]:\\n  input_text, target_text = line.split('\\\\t')\\n  val_input_texts.append(input_text)\\n  val_target_texts.append(target_text)\\n\\nval_encoder_input_data = np.zeros(\\n  (len(val_input_texts), max([len(txt) for txt in val_input_texts]),\\n   num_encoder_tokens), dtype='float32')\\n\\nfor i, input_text in enumerate(val_input_texts):\\n  for t, char in enumerate(input_text):\\n    val_encoder_input_data[i, t, input_token_index[char]] = 1.\", :output-log-lines {:stdout 0}, :language \"python\", :id \"f60adaea-4449-4657-a101-b1cffe2f3c6f\", :compute-ref #uuid \"734ba32e-7b8b-4658-ad81-374230e15b31\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 170, :bucket nil}, \"922ca13f-d75f-4146-bbd5-a1d3141b8907\" {:content \"import keras, tensorflow\\nfrom keras.models import Model\\nfrom keras.layers import Input, LSTM, Dense\\nimport numpy as np\", :output-log-lines {:stdout 1}, :language \"python\", :id \"922ca13f-d75f-4146-bbd5-a1d3141b8907\", :compute-ref #uuid \"42a990d6-ed37-4cfe-9470-3031c8cb1939\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 2603, :bucket nil}, \"ae6e9ac8-6b93-4531-bfb1-7d4273611f53\" {:stdout-collapsed? false, :content \"encoder_input_data[155].shape\", :output-log-lines {:stdout 0}, :language \"python\", :id \"ae6e9ac8-6b93-4531-bfb1-7d4273611f53\", :compute-ref #uuid \"8530f56d-91e5-4e14-ada2-3b885c4045c5\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 206, :bucket nil}, \"d6e7b3b7-02fc-4179-bf02-3e8efbe1bd42\" {:content \"for seq_index in range(10):\\n  input_seq = val_encoder_input_data[seq_index: seq_index + 1]\\n  decoded_sentence = decode_sequence(input_seq)\\n  print('-')\\n  print('Input sentence:', val_input_texts[seq_index])\\n  print('Decoded sentence:', decoded_sentence[:-1])\\n  print('Ground Truth sentence:', val_target_texts[seq_index])\", :output-log-lines {:stdout 40}, :language \"python\", :id \"d6e7b3b7-02fc-4179-bf02-3e8efbe1bd42\", :compute-ref #uuid \"a28cd9c7-43bd-402f-930d-bb7702807028\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 701, :bucket nil}, \"79ddf54b-429a-42c8-83f3-337e2ef53e8f\" {:content \"len(lines)\", :output-log-lines {:stdout 0}, :language \"python\", :id \"79ddf54b-429a-42c8-83f3-337e2ef53e8f\", :compute-ref #uuid \"408be837-bd60-456e-80e7-2e50c07a2b02\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 180, :bucket nil}, \"706a06f5-78ea-40df-a0b5-ff0d7e7b4f02\" {:content \"input_texts = []\\ntarget_texts = []\\ninput_characters = set()\\ntarget_characters = set()\", :output-log-lines {:stdout 0}, :language \"python\", :id \"706a06f5-78ea-40df-a0b5-ff0d7e7b4f02\", :compute-ref #uuid \"bbac13fb-28e2-4e47-a0a5-3449460dd888\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 248, :bucket nil}, \"dbd62d02-a197-430e-8482-f3c6cf6a214e\" {:content \"for line in lines[: min(num_samples, len(lines) - 1)]:\\n  input_text, target_text = line.split('\\\\t')\\n  target_text = '\\\\t' + target_text + '\\\\n'\\n  input_texts.append(input_text)\\n  target_texts.append(target_text)\\n  for char in input_text:\\n    if char not in input_characters:\\n      input_characters.add(char)\\n  for char in target_text:\\n    if char not in target_characters:\\n      target_characters.add(char)\", :output-log-lines {:stdout 0}, :language \"python\", :id \"dbd62d02-a197-430e-8482-f3c6cf6a214e\", :compute-ref #uuid \"e363ac97-519a-4b97-97b3-82daaef4c1e9\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 257, :bucket nil}, \"14616df3-a559-42d7-99e8-297f31f820c4\" {:content \"input_sentence = \\\"How are you?\\\"\\ntest_sentence_tokenized = np.zeros(\\n  (1, max_encoder_seq_length, num_encoder_tokens), dtype='float32')\\nfor t, char in enumerate(input_sentence):\\n  test_sentence_tokenized[0, t, input_token_index[char]] = 1.\\nprint(input_sentence)\\nprint(decode_sequence(test_sentence_tokenized))\", :output-log-lines {:stdout 3}, :language \"python\", :id \"14616df3-a559-42d7-99e8-297f31f820c4\", :compute-ref #uuid \"fa6a9e98-d126-460a-9fd4-d699b90d537b\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 417, :bucket nil}, \"f0c2078b-e5df-44ba-9e24-d5119081497b\" {:id \"f0c2078b-e5df-44ba-9e24-d5119081497b\", :kind \"code\", :content \"\", :language \"python\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"]}, \"eb9b4466-ba29-4e57-b2e6-e104ac1c4614\" {:content \"model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy')\\nmodel.load_weights($$ref{{[\\\"~:output\\\",\\\"a11b7a60-0d2b-49a8-b9b4-05a9cfcecd46\\\",\\\"seq2seq_eng-ger.h5\\\"]}})\", :output-log-lines {:stdout 3}, :language \"python\", :id \"eb9b4466-ba29-4e57-b2e6-e104ac1c4614\", :compute-ref #uuid \"e441edcb-2941-4417-85a2-3e805f13e539\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 1076, :bucket nil}, \"a5ee9c18-2bfd-4a9e-905b-4086fb5ba2df\" {:content \"print(target_characters)\", :output-log-lines {:stdout 1}, :language \"python\", :id \"a5ee9c18-2bfd-4a9e-905b-4086fb5ba2df\", :compute-ref #uuid \"9897a06a-3226-47b3-a0e1-cceda038413e\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 495, :bucket nil}, \"1a7c59d7-6717-45a0-a6f2-46410bbe649f\" {:content \"target_texts[155]\", :output-log-lines {:stdout 0}, :language \"python\", :id \"1a7c59d7-6717-45a0-a6f2-46410bbe649f\", :compute-ref #uuid \"bffb0ff8-95bc-4517-95b3-41fde9ba69b3\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 234, :bucket nil}, \"da1a59b6-dc60-4f27-a939-669d2babb80c\" {:content \"encoder_input_data.shape\", :output-log-lines {:stdout 0}, :language \"python\", :id \"da1a59b6-dc60-4f27-a939-669d2babb80c\", :compute-ref #uuid \"b0f0187b-fd44-46c0-b412-88ed5db0e686\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 247, :bucket nil}, \"f126bb18-7c37-46b4-bf57-457a87c7157d\" {:content \"print(input_characters)\", :output-log-lines {:stdout 1}, :language \"python\", :id \"f126bb18-7c37-46b4-bf57-457a87c7157d\", :compute-ref #uuid \"90c3a8b0-c232-4093-8931-6dcd8cb1ffac\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 415, :bucket nil}, \"84f5f376-ad88-4700-86c1-1784e01240b7\" {:ref-id \"ed0e0161-bd7d-4efd-93a2-aef4dc0c64bb\", :ref-kind \"output\", :id \"84f5f376-ad88-4700-86c1-1784e01240b7\", :kind \"reference\"}, \"553eab80-46ce-4c69-9f61-e7b61c47f5bb\" {:content \"def decode_sequence(input_seq):\\n  # encode the input sequence to get the internal state vectors.\\n  states_value = encoder_model.predict(input_seq)\\n  \\n  # generate empty target sequence of length 1 with only the start character\\n  target_seq = np.zeros((1, 1, num_decoder_tokens))\\n  target_seq[0, 0, target_token_index['\\\\t']] = 1.\\n  \\n  # output sequence loop\\n  stop_condition = False\\n  decoded_sentence = ''\\n  while not stop_condition:\\n    output_tokens, h, c = decoder_model.predict(\\n      [target_seq] + states_value)\\n    \\n    # sample a token and add the corresponding character to the \\n    # decoded sequence\\n    sampled_token_index = np.argmax(output_tokens[0, -1, :])\\n    sampled_char = reverse_target_char_index[sampled_token_index]\\n    decoded_sentence += sampled_char\\n    \\n    # check for the exit condition: either hitting max length\\n    # or predicting the 'stop' character\\n    if (sampled_char == '\\\\n' or \\n        len(decoded_sentence) > max_decoder_seq_length):\\n      stop_condition = True\\n      \\n    # update the target sequence (length 1).\\n    target_seq = np.zeros((1, 1, num_decoder_tokens))\\n    target_seq[0, 0, sampled_token_index] = 1.\\n    \\n    # update states\\n    states_value = [h, c]\\n    \\n  return decoded_sentence\", :output-log-lines {:stdout 0}, :language \"python\", :id \"553eab80-46ce-4c69-9f61-e7b61c47f5bb\", :compute-ref #uuid \"3c93059b-a109-4a24-8bbd-54bd8f0b668d\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 196, :bucket nil}, \"64ee66c7-5da1-4b49-b9a3-a40e5b9872b1\" {:content \"decoder_inputs = Input(shape=(None, num_decoder_tokens))\\ndecoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\\ndecoder_outputs, _, _ = decoder_lstm(decoder_inputs,\\n                                     initial_state=encoder_states)\\ndecoder_dense = Dense(num_decoder_tokens, activation='softmax')\\ndecoder_outputs = decoder_dense(decoder_outputs)\", :output-log-lines {:stdout 0}, :language \"python\", :id \"64ee66c7-5da1-4b49-b9a3-a40e5b9872b1\", :compute-ref #uuid \"5c244aef-4a2c-48ad-8f14-bb5c0d2888f7\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 752, :bucket nil}, \"b65c43c9-581a-4cd0-8ae6-56bb5a5db08a\" {:content \"model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\\nmodel.summary()\", :output-log-lines {:stdout 19}, :language \"python\", :id \"b65c43c9-581a-4cd0-8ae6-56bb5a5db08a\", :compute-ref #uuid \"7af823eb-13ec-4fca-b561-e44ba57517c4\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 547, :bucket nil}, \"1397847a-8a78-400f-809c-4bbd5f8b30fb\" {:content \"lines[155]\", :output-log-lines {:stdout 0}, :language \"python\", :id \"1397847a-8a78-400f-809c-4bbd5f8b30fb\", :compute-ref #uuid \"6da70a1d-1321-4705-b0f3-3c1339a5a2d5\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 189, :bucket nil}, \"fd3c6c92-740e-4b3d-9412-03fab04d2043\" {:content \"for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\\n  for t, char in enumerate(input_text):\\n    encoder_input_data[i, t, input_token_index[char]] = 1.\\n  for t, char in enumerate(target_text):\\n    # decoder_target_data is ahead of decoder_input_data by one timestep\\n    decoder_input_data[i, t, target_token_index[char]] = 1.\\n    if t > 0:\\n      # decoder_target_data will be ahead by one timestep\\n      # and will not include the start character.\\n      decoder_target_data[i, t - 1, target_token_index[char]] = 1.\", :output-log-lines {:stdout 0}, :language \"python\", :id \"fd3c6c92-740e-4b3d-9412-03fab04d2043\", :compute-ref #uuid \"f1a62d1a-1aff-42f9-a8ad-a0239df20f08\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 704, :bucket nil}, \"163950fa-c606-4e96-b75b-280eb0e443fd\" {:content \"input_token_index = dict(\\n  [(char, i) for i, char in enumerate(input_characters)])\\ntarget_token_index = dict(\\n  [(char, i) for i, char in enumerate(target_characters)])\", :output-log-lines {:stdout 0}, :language \"python\", :id \"163950fa-c606-4e96-b75b-280eb0e443fd\", :compute-ref #uuid \"bbb1cb19-9a72-4046-b3e4-393af4e66673\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 293, :bucket nil}, \"a66de03c-e007-4e23-a107-eda95b659686\" {:content \"import numpy as np\\n\\nencoder_input_data = np.zeros(\\n  (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\\n  dtype='float32')\\ndecoder_input_data = np.zeros(\\n  (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\\n  dtype='float32')\\ndecoder_target_data = np.zeros(\\n  (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\\n  dtype='float32')\", :output-log-lines {:stdout 0}, :language \"python\", :id \"a66de03c-e007-4e23-a107-eda95b659686\", :compute-ref #uuid \"8c67e271-03b7-4b8c-a1f3-1f545af1320d\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 195, :bucket nil}, \"17881553-d7bd-4573-a980-8217170e5774\" {:content \"input_characters = sorted(list(input_characters))\\ntarget_characters = sorted(list(target_characters))\\nnum_encoder_tokens = len(input_characters)\\nnum_decoder_tokens = len(target_characters)\\nmax_encoder_seq_length = max([len(txt) for txt in input_texts])\\nmax_decoder_seq_length = max([len(txt) for txt in target_texts])\\n\\nprint('Number of samples:', len(input_texts))\\nprint('Number of unique input tokens:', num_encoder_tokens)\\nprint('Number of unique output tokens:', num_decoder_tokens)\\nprint('Max sequence length for inputs:', max_encoder_seq_length)\\nprint('Max sequence length for outputs:', max_decoder_seq_length)\", :output-log-lines {:stdout 5}, :language \"python\", :id \"17881553-d7bd-4573-a980-8217170e5774\", :compute-ref #uuid \"1125b5eb-6575-40c6-949f-2d352fd77bf2\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 424, :bucket nil}, \"45693bc9-32d8-4991-8079-20bac84f7a65\" {:content \"encoder_inputs = Input(shape=(None, num_encoder_tokens))\\nencoder = LSTM(latent_dim, return_state=True)\\nencoder_outputs, state_h, state_c = encoder(encoder_inputs)\\nencoder_states = [state_h, state_c]\", :output-log-lines {:stdout 0}, :language \"python\", :id \"45693bc9-32d8-4991-8079-20bac84f7a65\", :compute-ref #uuid \"6141b72c-218a-443b-8d2c-54fcc9f78869\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 956, :bucket nil}, \"57ed9915-dc0b-4ee0-8527-47e3d27e1f6c\" {:id \"57ed9915-dc0b-4ee0-8527-47e3d27e1f6c\", :kind \"reference\", :link [:output \"a11b7a60-0d2b-49a8-b9b4-05a9cfcecd46\" \"seq2seq_eng-ger.h5\"]}, \"26c7f68c-0a76-488e-88af-3ccc1086610e\" {:content \"decoder_input_data.shape\", :output-log-lines {:stdout 0}, :language \"python\", :id \"26c7f68c-0a76-488e-88af-3ccc1086610e\", :compute-ref #uuid \"0dc1ce69-2e6e-409c-a345-652d78e56592\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 199, :bucket nil}, \"3eef4c19-9982-4d1f-be1b-f635c185e311\" {:content \"# reverse-lookup token index to turn sequences back to characters\\nreverse_input_char_index = dict(\\n  (i, char) for char, i in input_token_index.items())\\nreverse_target_char_index = dict(\\n  (i, char) for char, i in target_token_index.items())\", :output-log-lines {:stdout 0}, :language \"python\", :id \"3eef4c19-9982-4d1f-be1b-f635c185e311\", :compute-ref #uuid \"0e6130ef-ff01-4fd9-9ad0-e7e0241487b9\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 195, :bucket nil}, \"1e35f556-99c4-4404-aef6-80eecef36cd2\" {:content \"model = Model(inputs=[encoder_inputs, decoder_inputs], \\n              outputs=decoder_outputs)\", :output-log-lines {:stdout 0}, :language \"python\", :id \"1e35f556-99c4-4404-aef6-80eecef36cd2\", :compute-ref #uuid \"f6efe561-d50c-4c9f-95a4-04bb6903e80b\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 202, :bucket nil}, \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\" {:runtime/inherited-environment-variables ({:name \"PATH\", :value \"/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"} {:name \"MPLBACKEND\", :value \"svg\"} {:name \"LC_ALL\", :value \"en_US.UTF-8\"} {:name \"LANGUAGE\", :value \"en_US.en\"} {:name \"LANG\", :value \"en_US.UTF-8\"} {:name \"DEBIAN_FRONTEND\", :value \"noninteractive\"} {:name \"BASH_ENV\", :value \"/.bash_profile\"} {:name \"LD_LIBRARY_PATH\", :value \"/usr/local/nvidia/lib64/:/usr/local/cuda/lib64/\"}), :name \"Keras Runtime\", :type :nextjournal, :language \"python\", :id \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\", :compute-ref #uuid \"c81ad670-e9e7-11e9-8bc7-53085b1d322f\", :kind \"runtime\", :error nil, :environment [:environment {:article/nextjournal.id #uuid \"59cd6480-79c8-4e95-a73f-e3e39ba9f52c\", :change/nextjournal.id #uuid \"5b489c2a-559e-413e-92b1-e7f9339a7646\", :node/id \"cf8e6214-03e3-4662-9f39-b40673a6c19c\"}], :resources {:machine-type \"n1-standard-1\"}}, \"c5329f01-27a1-4f2c-ad0c-3837bc52399a\" {:content \"for seq_index in range(10):\\n  input_seq = encoder_input_data[seq_index: seq_index + 1]\\n  decoded_sentence = decode_sequence(input_seq)\\n  print('-')\\n  print('Input sentence:', input_texts[seq_index])\\n  print('Decoded sentence:', decoded_sentence)\", :output-log-lines {:stdout 40}, :language \"python\", :id \"c5329f01-27a1-4f2c-ad0c-3837bc52399a\", :compute-ref #uuid \"97833178-4b8b-445d-8450-fe68da1a30ac\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 629, :bucket nil}, \"2787b229-44c6-4018-8152-40f67e16621f\" {:content \"\", :output-log-lines {:stdout 0}, :language \"python\", :id \"2787b229-44c6-4018-8152-40f67e16621f\", :compute-ref #uuid \"f4942b80-9513-415c-9d1d-94f8da215f19\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 294}, \"ed0e0161-bd7d-4efd-93a2-aef4dc0c64bb\" {:content \"num_samples = 10000\\nnum_samples\", :output-log-lines {:stdout 0}, :language \"python\", :id \"ed0e0161-bd7d-4efd-93a2-aef4dc0c64bb\", :compute-ref #uuid \"2c30618b-d207-4a1c-98bd-b49b4b0b4b4e\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 236, :bucket nil}, \"0f3910e7-f41d-45eb-a6e3-686bf651bd49\" {:content \"max([len(txt) for txt in val_input_texts])\", :output-log-lines {:stdout 0}, :language \"python\", :id \"0f3910e7-f41d-45eb-a6e3-686bf651bd49\", :compute-ref #uuid \"9ffc1887-be2b-4a42-acda-73a775477e32\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 266, :bucket nil}, \"28439d61-43a3-4ee1-a767-731e6ccfdcfa\" {:content \"encoder_model = Model(encoder_inputs, encoder_states)\\n\\ndecoder_state_input_h = Input(shape=(latent_dim,))\\ndecoder_state_input_c = Input(shape=(latent_dim,))\\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\\n\\ndecoder_outputs, state_h, state_c = decoder_lstm(\\n  decoder_inputs, initial_state=decoder_states_inputs)\\ndecoder_states = [state_h, state_c]\\ndecoder_outputs = decoder_dense(decoder_outputs)\\n\\ndecoder_model = Model(\\n  [decoder_inputs] + decoder_states_inputs,\\n  [decoder_outputs] + decoder_states)\", :output-log-lines {:stdout 0}, :language \"python\", :id \"28439d61-43a3-4ee1-a767-731e6ccfdcfa\", :compute-ref #uuid \"dfbbca7d-cee5-4767-afd6-eddba0200143\", :runtime [:runtime \"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e\"], :kind \"code\", :error nil, :exec-duration 429, :bucket nil}}","runtime-id":"3083bc75-7f21-4bdf-b495-5e5dc9c6af0e","url":"https://nextjournal.com/gkoehler/machine-translation-seq2seq-cpu"}},"nbformat":4,"nbformat_minor":4}
